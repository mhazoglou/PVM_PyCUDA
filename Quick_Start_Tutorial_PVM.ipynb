{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and formatting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a guide that will download and process the data used in https://arxiv.org/abs/1607.06854\n",
    "once the data is downloaded and processed there is no need to rerun the code below the import\n",
    "statements in the next cell unit the next titled section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be useful if you need to reload any module after some changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycuda import gpuarray, compiler\n",
    "from collections import OrderedDict\n",
    "import requests as req\n",
    "import bs4\n",
    "import shutil\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for downloading files from a link\n",
    "\n",
    "def download_file(url, path=''):\n",
    "    local_filename = path + url.split('/')[-1]\n",
    "    r = req.get(url, stream=True)\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading files to the specified download path into a folder\n",
    "# called PVM_zipped_set\n",
    "\n",
    "download_path = '~/Downloads/' # press tab for autocomplete results\n",
    "root = download_path + 'PVM_zipped_set/'\n",
    "if root.rsplit('/')[-2] not in os.listdir(download_path):\n",
    "    os.mkdir(root)\n",
    "\n",
    "webpage = 'http://pvm.braincorporation.net/'\n",
    "r = req.get(webpage)\n",
    "html_doc = r.content\n",
    "soup = bs4.BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "for link in soup.find_all('a'):\n",
    "    link_ext = link.get('href')\n",
    "    if 'PVM_set/' in link_ext:\n",
    "        print(download_file(webpage + link_ext, path=root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the zipped folders\n",
    "dirlist = os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming some of the face and stop sets to be testing data\n",
    "# you can choose other arrangements like all odd/even videos\n",
    "# are part of the testing set\n",
    "\n",
    "for zip_file in dirlist:\n",
    "    if 'face' in zip_file:\n",
    "        count = int(zip_file[4:6])\n",
    "        if count > 10:\n",
    "            try:\n",
    "                os.rename(root + zip_file,\n",
    "                          root + 'face_test_' + str(count) + '.zip')\n",
    "            except OSError:\n",
    "                pass\n",
    "    elif 'stop' in zip_file:\n",
    "        count = int(zip_file[4:6])\n",
    "        if count > 20:\n",
    "            try:\n",
    "                os.rename(root + zip_file,\n",
    "                          root + 'stop_test_' + str(count) + '.zip')\n",
    "            except OSError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading the names of the zipped folders after the renaming\n",
    "dirlist = os.listdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzipping and splitting training and testing data\n",
    "import zipfile\n",
    "\n",
    "test_path = download_path + 'PVM_test_set/'\n",
    "train_path = download_path + 'PVM_train_set/'\n",
    "\n",
    "\n",
    "if test_path.split('/')[-1] not in os.listdir(download_path):\n",
    "    os.mkdir(test_path)\n",
    "    \n",
    "if train_path.split('/')[-1] not in os.listdir(download_path):\n",
    "    os.mkdir(train_path)\n",
    "\n",
    "for dir_ in dirlist:\n",
    "    with zipfile.ZipFile(root + dir_, \"r\") as zip_ref:\n",
    "        base_name = dir_[:-4]\n",
    "        if 'test' in base_name:\n",
    "            zip_ref.extractall(test_path)\n",
    "        else:\n",
    "            zip_ref.extractall(train_path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a hdf5_raw_data to resize and save frames from the multiple \n",
    "# videos into and hdf5 file format these are great for large sets of\n",
    "# data and can be manipulated directly from storage\n",
    "from FormattingFiles import hdf5_raw_data\n",
    "\n",
    "train_filename = download_path + 'PVM_train_set.hdf5'\n",
    "test_filename = download_path + 'PVM_test_set.hdf5'\n",
    "new_size = (96, 96)\n",
    "hdf5_raw_data(train_path, train_filename, new_size, img_dir='img')\n",
    "hdf5_raw_data(test_path, test_filename, new_size, img_dir='img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a PVM instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have run the previous cell you should have all the files you need. You\n",
    "will not need to rerun anything from above besides the first cell of import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick your device the default is 0 if not specified if the next line is not commented\n",
    "os.environ['CUDA_DEVICE'] = '1' \n",
    "\n",
    "# autoinit automatically initializes a CUDA context\n",
    "import pycuda.autoinit\n",
    "\n",
    "from PVM_PyCUDA import OnTheFlyPVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters for the PVM they are different from the original paper\n",
    "n_color = 3\n",
    "input_edge = 1\n",
    "input_size = input_edge * input_edge * n_color\n",
    "hidden_size = 8\n",
    "output_sizes = [0] * 8\n",
    "structure = [96, 48, 24, 12, 6, 3, 2, 1]\n",
    "\n",
    "edge_n_pixels = input_edge * structure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing two functions for mapping and unmapping and image into a\n",
    "# one dimensional array\n",
    "from FormattingFiles import flatten_image, unflatten_image\n",
    "# importing a function to give a connection dictionary\n",
    "from RectangularGridConstructor import make_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize any instance of a PVM you need to specify how it's connected\n",
    "# this can be as general as you want in principle as connectivity is \n",
    "# defined in dictionary. The function make_connections is a way to \n",
    "# construct a layered hierarchy of rectangular grids with nearest neighbor lateral connections\n",
    "# was done in the paper\n",
    "connect_dict = make_connections(structure, input_size, hidden_size, output_sizes, context_from_top_0_0=True)\n",
    "\n",
    "# dim is a tuple (height, width, number of colors)\n",
    "dim = (edge_n_pixels, edge_n_pixels, 3)\n",
    "input_shape = (input_edge, input_edge)\n",
    "basic_index = np.arange(np.prod(dim)).reshape(dim)\n",
    "flat_map = flatten_image(basic_index, input_shape)\n",
    "rev_flat_map = np.sort(flat_map).reshape(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't need to rerun stuff after it's been saved\n",
    "download_path = '~/Downloads/' # press tab for autocomplete results\n",
    "train_filename = download_path + 'PVM_train_set.hdf5'\n",
    "test_filename = download_path + 'PVM_test_set.hdf5'\n",
    "\n",
    "train_data = h5py.File(train_filename, 'r')\n",
    "test_data_reformat_nontracker =  h5py.File(test_filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvm = OnTheFlyPVM(connect_dict, flat_map, norm=255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/path/to/files' # choose the path and filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if model has already been trained and parameters have been saved\n",
    "pvm.load_parameters(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [0.01] * 3000000 \n",
    "# You may want to change the length of this if you want to change the amount of time trained\n",
    "# If I remember correctly 3 million frames at a training rate of 0.01 gives good results \n",
    "# comparable to the original paper\n",
    "\n",
    "# this will train the model with the training schedule specified by learning_rate_list\n",
    "# on the training data in train_data, print_every says how often it will print the results\n",
    "# of training, save_every_print set to True will save the model parameters and a plot of\n",
    "# the MSE averaged over the number of frames given in interval, the parameters, plot and \n",
    "# connections will be saved in three different files with the name given in filename\n",
    "pvm.train(train_data, learning_rate_list,\n",
    "          print_every=100000, save_every_print=True, \n",
    "          filename=fname, interval=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively use ADAM to train the PVM with default hyperparameters\n",
    "N_epoch = 60 \n",
    "pvm.adam_train(train_data, N_epoch, L2_norm_reg=0,\n",
    "               print_every_epoch=True, save_every_print=True,\n",
    "               filename=fname, interval=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animating PVM predictions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A relatively new method for quick visualization\n",
    "# keyboard interrupt is does not work in Jupyter you need to interrupt\n",
    "# the kernel\n",
    "pvm.quick_animate(test_data_reformat_nontracker, scale=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "%matplotlib tk\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "\n",
    "unflattened_idx_array = rev_flat_map # not a copy\n",
    "L_y = edge_n_pixels\n",
    "L_x = edge_n_pixels\n",
    "\n",
    "def gen_func():\n",
    "    global test_data_reformat_nontracker, pvm\n",
    "    for key, rescale_arr in test_data_reformat_nontracker.items():\n",
    "        n_frame, height, width, n_colors = rescale_arr.shape\n",
    "        \n",
    "        pvm.reset_state()\n",
    "        for i in range(n_frame):\n",
    "            image = rescale_arr[i, ...]\n",
    "            pvm.forward(image)\n",
    "            yield image, pvm.pred[:pvm.L_input].get(),\\\n",
    "                pvm.err[:pvm.L_input].get()\n",
    "                \n",
    "def update(vals):\n",
    "    global L_y, L_x\n",
    "    image, pred, err = vals\n",
    "    reordered_err = err[unflattened_idx_array]\n",
    "    mag_err = abs(reordered_err - 0.5)\n",
    "    \n",
    "    im1 = ax1.imshow(image, animated=True)\n",
    "        \n",
    "    im2 = ax2.imshow(pred[unflattened_idx_array], animated=True)\n",
    "\n",
    "    im3 = ax3.imshow(mag_err, animated=True)\n",
    "    \n",
    "    return im1, im2, im3\n",
    "\n",
    "vals = next(gen_func())\n",
    "image, pred, err = vals\n",
    "reordered_err = err[unflattened_idx_array]\n",
    "mag_err = abs(reordered_err - 0.5)\n",
    "\n",
    "im1 = ax1.imshow(image, animated=True)\n",
    "\n",
    "im2 = ax2.imshow(pred[unflattened_idx_array], animated=True)\n",
    "\n",
    "im3 = ax3.imshow(mag_err, animated=True)\n",
    "ani = animation.FuncAnimation(fig, update, frames=gen_func,\n",
    "                              interval=5, blit=True, save_count=30*(10*60))\n",
    "\n",
    "# This takes too long so avoid saving video if you don't have to\n",
    "# ani.save('SaveVideo.mp4',\n",
    "#          writer='ffmpeg', fps=30, bitrate=-1,\n",
    "#          extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
