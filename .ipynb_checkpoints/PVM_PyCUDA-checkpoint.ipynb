{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function, division\n",
    "from builtins import *\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from pycuda import driver, compiler, gpuarray, tools\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE'] = '0' # pick your device\n",
    "\n",
    "# -- initialize the device\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "datapath = '/media/sdb/green_ball/'\n",
    "filelist = os.listdir(datapath)\n",
    "\n",
    "nparrayfile = re.compile('(.+?)\\.npy')\n",
    "csvfile = re.compile('(.+?)\\.csv')\n",
    "testfile_exp = re.compile('.+?test.+?')\n",
    "\n",
    "test_data = {}\n",
    "train_data = {}\n",
    "did_it = []\n",
    "for filename in filelist:\n",
    "    filename_wo_ext = filename.rsplit('.', 1)[0]\n",
    "    if filename_wo_ext not in did_it:\n",
    "        fname = datapath + filename_wo_ext\n",
    "        arr = np.load(fname + '.npy')\n",
    "        df = pd.read_csv(fname + '.csv')\n",
    "\n",
    "        if testfile_exp.match(filename) is None:\n",
    "            train_data[filename_wo_ext] = (arr, df)\n",
    "        else:\n",
    "            test_data[filename_wo_ext] = (arr, df)\n",
    "        did_it.append(filename_wo_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_edge = 6\n",
    "n_color = 3\n",
    "input_size = input_edge * input_edge * n_color\n",
    "hidden_size = 49\n",
    "output_sizes = [1, 2*2, 4*4, 8*8, 6*6, 16*16]\n",
    "heat_map_size = 256\n",
    "structure = [16, 8, 4, 3, 2, 1]\n",
    "\n",
    "edge_n_pixels = input_edge*structure[0]\n",
    "heat_map_edge = int(math.sqrt(heat_map_size))\n",
    "\n",
    "train_data_reformat = {}\n",
    "for key, data_and_label in train_data.items():\n",
    "    data_arr, df = data_and_label\n",
    "    n_frames = len(df)\n",
    "\n",
    "\n",
    "    rescale_arr = data_arr/255.\n",
    "    ground_truth_heat_map_list = []\n",
    "    for idx in range(n_frames):\n",
    "        rescale_factor = heat_map_edge / edge_n_pixels\n",
    "        x, y, x_w, y_w = rescale_factor * df.iloc[idx]\n",
    "        # keep in mind that this only works because the values\n",
    "        # that are negative are factions because of the scaling down\n",
    "        # if I were to keep the image the same size the frames with no\n",
    "        # ball would still give x, y, x_w, y_w = -1\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        x_w = int(x_w)\n",
    "        y_w = int(y_w)\n",
    "        ground_truth_heat_map = np.zeros((heat_map_edge, heat_map_edge))\n",
    "\n",
    "        ground_truth_heat_map[y:y+y_w, x:x+x_w] = 1\n",
    "        ground_truth_heat_map = ground_truth_heat_map.reshape(heat_map_size)\n",
    "        ground_truth_heat_map_list.append(ground_truth_heat_map)\n",
    "        \n",
    "    train_data_reformat[key] = (rescale_arr, ground_truth_heat_map_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PVM_PyCUDA import PVM_CUDA, PVMtracker\n",
    "from RectangularGridConstructor import make_connections\n",
    "\n",
    "# resultpath = './GreenBallTraining/'\n",
    "# filename = resultpath + 'green_ball_learning_rate_0.01_hidden_49_3000000steps'\n",
    "# dir_list = os.listdir('./')\n",
    "# if resultpath.split('/')[1] not in dir_list:\n",
    "#     os.mkdir(resultpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connect_dict = make_connections(structure, output_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker = PVMtracker(structure, output_sizes, heat_map_size, input_size, hidden_size, context_from_top_0_0=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultpath = './GreenBallTraining/'\n",
    "filename = resultpath + 'green_ball_learning_rate_0.01_hidden_49_5000000steps'\n",
    "tracker.load_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100000 frames: 0.00741105504244\n",
      "    200000 frames: 0.00516860081658\n",
      "    300000 frames: 0.00473766347278\n",
      "    400000 frames: 0.00449034257444\n",
      "    500000 frames: 0.00441235010534\n",
      "    600000 frames: 0.00429010623325\n",
      "    700000 frames: 0.00427266457775\n",
      "    800000 frames: 0.0041830899829\n",
      "    900000 frames: 0.00419109633875\n",
      "   1000000 frames: 0.00410702779253\n",
      "   1100000 frames: 0.00414249707359\n",
      "   1200000 frames: 0.00406286576883\n",
      "   1300000 frames: 0.00409605852761\n",
      "   1400000 frames: 0.00403729559867\n",
      "   1500000 frames: 0.00405114192711\n",
      "   1600000 frames: 0.00402921508202\n",
      "   1700000 frames: 0.00400914999289\n",
      "   1800000 frames: 0.00402255315661\n",
      "   1900000 frames: 0.00399040191548\n",
      "   2000000 frames: 0.0040089247076\n",
      "   2100000 frames: 0.00396746342339\n",
      "   2200000 frames: 0.00400348520676\n",
      "   2300000 frames: 0.00396162847154\n",
      "   2400000 frames: 0.00399585937487\n",
      "   2500000 frames: 0.00394929680966\n",
      "   2600000 frames: 0.00398794913605\n",
      "   2700000 frames: 0.00393103658187\n",
      "   2800000 frames: 0.00398270361585\n",
      "   2900000 frames: 0.0039252125032\n",
      "   3000000 frames: 0.00396855385592\n",
      "   3100000 frames: 0.00392737574441\n",
      "   3200000 frames: 0.00395175163202\n",
      "   3300000 frames: 0.00394038544842\n",
      "   3400000 frames: 0.00393028559344\n",
      "   3500000 frames: 0.00395143560493\n",
      "   3600000 frames: 0.00392685575695\n",
      "   3700000 frames: 0.00395152828917\n",
      "   3800000 frames: 0.00391433556768\n",
      "   3900000 frames: 0.00395735344983\n",
      "   4000000 frames: 0.00391844861024\n",
      "   4100000 frames: 0.00395906278542\n",
      "   4200000 frames: 0.00391603423493\n",
      "   4300000 frames: 0.00396088193132\n",
      "   4400000 frames: 0.00390762364142\n",
      "   4500000 frames: 0.00396379662976\n",
      "   4600000 frames: 0.00391085510088\n",
      "   4700000 frames: 0.00395599773868\n",
      "   4800000 frames: 0.00391697431702\n",
      "   4900000 frames: 0.00394218749038\n",
      "   5000000 frames: 0.00393235845919\n"
     ]
    }
   ],
   "source": [
    "resultpath = './GreenBallTraining/'\n",
    "filename = resultpath + 'green_ball_learning_rate_0.01_hidden_49_5000000steps'\n",
    "dir_list = os.listdir('./')\n",
    "if resultpath.split('/')[1] not in dir_list:\n",
    "    os.mkdir(resultpath)\n",
    "learning_rate_list = [0.01]*5000000 #[0.0002]*1000000 + [0.00005]*1500000 + [0.00001]*39000000\n",
    "tracker.train(train_data_reformat, learning_rate_list, print_every=100000,\n",
    "              save_every_print=False, filename=filename, interval=100000)\n",
    "tracker.save_mse(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from FormattingFiles import norm_and_heatmap, unflatten_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_reformat = {}\n",
    "for key, data in test_data.items():\n",
    "    data_arr, df = data\n",
    "    \n",
    "    test_data_reformat[key] = norm_and_heatmap(data_arr, df, heat_map_edge, edge_n_pixels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_threshold = 0.6\n",
    "precision_threshold = 20 * 16 / 96\n",
    "success_list, precision_list, accuracy_list = tracker.test(test_data_reformat, \n",
    "                                                           (heat_map_edge, heat_map_edge),\n",
    "                                                           success_threshold,\n",
    "                                                           precision_threshold,\n",
    "                                                           accuracy_threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.71367510363828313, 0.87831191904627026, 0.88549579009707235)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(success_list), np.mean(precision_list), np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cutting some stuff of memory\n",
    "del train_data, train_data_reformat, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving animation works better with ArtistAnimation\n",
    "# %matplotlib tk\n",
    "\n",
    "heat_map_edges = (heat_map_edge, heat_map_edge)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "\n",
    "ims = []\n",
    "for key, data in test_data_reformat.items():\n",
    "    rescale_arr, ground_truth_heat_map_list = data\n",
    "    n_frame = len(ground_truth_heat_map_list)\n",
    "    tracker.reset_state()\n",
    "    for i in range(n_frame):\n",
    "        flat_image = rescale_arr[i,:]#(256 - (255 * (rescale_arr[i,:])).astype(np.int8))\n",
    "        tracker.forward(flat_image)\n",
    "        \n",
    "        im1 = ax1.imshow(unflatten_image(flat_image,\n",
    "                                         (edge_n_pixels,edge_n_pixels, n_color),\n",
    "                                         (input_edge, input_edge)), animated=True)\n",
    "        \n",
    "         \n",
    "#         im2 = ax2.imshow(unflatten_image(abs(flat_image - tracker.pred[:tracker.L_input].get()),\n",
    "#                                          (edge_n_pixels, edge_n_pixels, n_color),\n",
    "#                                          (input_edge, input_edge)), animated=True)\n",
    "        \n",
    "        im2 = ax2.imshow(unflatten_image(tracker.pred[:tracker.L_input].get(),\n",
    "                                         (edge_n_pixels, edge_n_pixels, n_color),\n",
    "                                         (input_edge, input_edge)), animated=True)\n",
    "        \n",
    "        im3 = ax3.imshow(ground_truth_heat_map_list[i].reshape(heat_map_edges),\n",
    "                         cmap='gray', animated=True)\n",
    "        \n",
    "        im4 = ax4.imshow(tracker.avg_heatmap.get().reshape(heat_map_edges),\n",
    "                         vmin=0, vmax=1, cmap='gray', animated=True)\n",
    "        ims.append([im1, im2, im3, im4])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000/60, blit=True)\n",
    "ani.save(resultpath + 'green_ball_learning_rate_0.01_hidden_49_5000000steps.mp4',\n",
    "         writer='ffmpeg', fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# realtime animation\n",
    "%matplotlib tk\n",
    "\n",
    "heat_map_edges = (heat_map_edge, heat_map_edge)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "\n",
    "def gen_func():\n",
    "    global test_data_reformat, tracker\n",
    "    for key, data in test_data_reformat.items():\n",
    "        rescale_arr, ground_truth_heat_map_list = data\n",
    "        n_frame = len(ground_truth_heat_map_list)\n",
    "        tracker.reset_state()\n",
    "        for i in range(n_frame):\n",
    "            flat_image = rescale_arr[i,:]#(256 - (255 * (rescale_arr[i,:])).astype(np.int8))\n",
    "            tracker.forward(flat_image)\n",
    "            yield flat_image, tracker.pred[:tracker.L_input].get(),\\\n",
    "                ground_truth_heat_map_list[i], tracker.avg_heatmap.get()\n",
    "                \n",
    "def update(vals):\n",
    "    flat_image, pred, gt_heat_map, heatmap = vals\n",
    "    im1 = ax1.imshow(unflatten_image(flat_image,\n",
    "                                     (edge_n_pixels,edge_n_pixels, n_color),\n",
    "                                     (input_edge, input_edge)), animated=True)\n",
    "        \n",
    "        \n",
    "    im2 = ax2.imshow(unflatten_image(abs(flat_image - pred),\n",
    "                                     (edge_n_pixels, edge_n_pixels, n_color),\n",
    "                                     (input_edge, input_edge)), animated=True)\n",
    "\n",
    "    im3 = ax3.imshow(gt_heat_map.reshape(heat_map_edges),\n",
    "                     cmap='gray', animated=True)\n",
    "\n",
    "    im4 = ax4.imshow(heatmap.reshape(heat_map_edges),\n",
    "                     vmin=0, vmax=1, cmap='gray', animated=True)\n",
    "    return im1, im2, im3, im4\n",
    "\n",
    "vals = gen_func().next()\n",
    "flat_image, pred, gt_heat_map, heatmap = vals\n",
    "im1 = ax1.imshow(unflatten_image(flat_image,\n",
    "                                 (edge_n_pixels,edge_n_pixels, n_color),\n",
    "                                 (input_edge, input_edge)), animated=True)\n",
    "\n",
    "\n",
    "im2 = ax2.imshow(unflatten_image(pred,\n",
    "                                 (edge_n_pixels, edge_n_pixels, n_color),\n",
    "                                 (input_edge, input_edge)), animated=True)\n",
    "\n",
    "im3 = ax3.imshow(gt_heat_map.reshape(heat_map_edges),\n",
    "                 cmap='gray', animated=True)\n",
    "\n",
    "im4 = ax4.imshow(heatmap.reshape(heat_map_edges),\n",
    "                 vmin=0, vmax=1, cmap='gray', animated=True)\n",
    "ani = animation.FuncAnimation(fig, update, frames=gen_func, interval=16, blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00070687,  0.02102356,  0.01186935, ...,  0.03868137,\n",
       "         0.03213972, -0.00101318]),\n",
       " array([  1.13520786e-03,   1.80932772e-02,   1.28967698e-02, ...,\n",
       "         -3.56679307e-02,  -1.66260265e-05,  -4.96235665e-02]),\n",
       " array([  3.68078829e-07,   2.85900087e-07,   3.56774643e-07, ...,\n",
       "          1.10296916e-06,   3.12090251e-07,   1.54280066e-07]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.grad_bias_h2op, tracker.grad_bias_i2h, tracker.delta_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.58924490e-06,   6.82992561e-04,   3.16866442e-04, ...,\n",
       "         -5.20864310e-04,  -1.01311242e-03,  -3.77799398e-04]),\n",
       " array([ 0.00059209,  0.00030272,  0.00019588, ..., -0.03295553,\n",
       "        -0.04961997, -0.01737747]),\n",
       " array([  1.71262927e-07,   6.71469537e-08,   6.14081263e-08, ...,\n",
       "          1.20036118e-07,   1.15290952e-07,   1.88227648e-08]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.grad_weight_h2op, tracker.grad_weight_i2h, tracker.grad_weight_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker2 = PVMtracker(structure, output_sizes, heat_map_size, input_size, hidden_size, context_from_top_0_0=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker2.load_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker2.h2op_bias.get() - tracker.h2op_bias.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tracker.save_parameters('green_ball_training_experiment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracker.i2h_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracker.load_parameters('./test_save_parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tracker.i2h_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     n = raw_input(\"Please enter 'hello':\")\n",
    "#     if n.strip() == 'hello':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_reformat['green_ball_01_small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feeds2(structure, layer, x, y):\n",
    "    \"\"\"\n",
    "    Specifies which PVM-units the location layer, x, y\n",
    "    feeds to in the next layer assuming that the structure is\n",
    "    rectangular and doesn't differ along an edge by more than 1 unit\n",
    "    or by double the dimension of units\n",
    "    \"\"\"\n",
    "    assert layer < len(structure) - 1\n",
    "    \n",
    "    def shape_check(shape):\n",
    "        if isinstance(shape, int):\n",
    "            L_x = shape\n",
    "            L_y = shape\n",
    "        elif len(shape) == 2:\n",
    "            L_x, L_y = shape\n",
    "        elif len(shape) == 1:\n",
    "            L_x = shape[0]\n",
    "            L_y = shape[0]\n",
    "        else:\n",
    "            raise ValueError('Not a valid entry must be a single integer\\n' +\n",
    "                         'or a tuple of length one or two.')\n",
    "        return L_x, L_y\n",
    "    \n",
    "    def find_edge_pos_upper_layer(pos, L, L_n):\n",
    "        if (L - L_n) == 1:\n",
    "            if pos == 0:\n",
    "                p_list = [0]\n",
    "            elif pos == L-1:\n",
    "                p_list = [L_n-1]\n",
    "            else:\n",
    "                p_list = [pos-1, pos]\n",
    "        elif L/L_n % 2 == 0:\n",
    "            pos_ov2 = pos / 2\n",
    "            p_list = [int(pos_ov2 - pos_ov2 % 1)]\n",
    "        elif L == L_n:\n",
    "            p_list = [pos]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Underlying assumption about layer structure violated.\\n'+\n",
    "                'Edge sizes must differ by at most 1 or a mutliple of 2')\n",
    "        return p_list\n",
    "    \n",
    "    shape = structure[layer]\n",
    "    L_x, L_y = shape_check(shape)\n",
    "    \n",
    "    \n",
    "    shape_next = structure[layer+1]\n",
    "    L_x_n, L_y_n = shape_check(shape_next)\n",
    "    \n",
    "    p_x_list = find_edge_pos_upper_layer(x, L_x, L_x_n)\n",
    "    p_y_list = find_edge_pos_upper_layer(y, L_y, L_y_n)\n",
    "    \n",
    "    feed2List = []\n",
    "    for p_x in p_x_list:\n",
    "        feed2List += [(p_x, p_y) for p_y in p_y_list]\n",
    "        \n",
    "    return feed2List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fedfrom(structure, layer, x, y):\n",
    "    \"\"\"\n",
    "    Specifies which PVM-units the location layer, x, y is fed\n",
    "    from in the layer directly below assuming that the structure is\n",
    "    rectangular and doesn't differ along an edge by more than 1 unit\n",
    "    or by double the dimension of units\n",
    "    \"\"\"\n",
    "    assert layer > 0\n",
    "    \n",
    "    def shape_check(shape):\n",
    "        if isinstance(shape, int):\n",
    "            L_x = shape\n",
    "            L_y = shape\n",
    "        elif len(shape) == 2:\n",
    "            L_x, L_y = shape\n",
    "        elif len(shape) == 1:\n",
    "            L_x = shape[0]\n",
    "            L_y = shape[0]\n",
    "        else:\n",
    "            assert len(shape) < 2 and len(shape) > 0\n",
    "        return L_x, L_y\n",
    "    \n",
    "    def find_edge_pos_lower_layer(pos, L, L_b):\n",
    "        if (L_b - L) == 1:\n",
    "            p_list = [pos, pos + 1]\n",
    "        elif L_b/L % 2 == 0:\n",
    "            pos_doub = 2*pos\n",
    "            p_list = [pos_doub, pos_doub+1]\n",
    "        elif L == L_b:\n",
    "            p_list = [pos]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Underlying assumption about layer structure violated.\\n'+\n",
    "                'Edge sizes must differ by at most 1 or a mutliple of 2')\n",
    "        return p_list\n",
    "    \n",
    "    shape = structure[layer]\n",
    "    L_x, L_y = shape_check(shape)\n",
    "    \n",
    "    \n",
    "    shape_b = structure[layer-1]\n",
    "    L_x_b, L_y_b = shape_check(shape_b)\n",
    "    \n",
    "    p_x_list = find_edge_pos_lower_layer(x, L_x, L_x_b)\n",
    "    p_y_list = find_edge_pos_lower_layer(y, L_y, L_y_b)\n",
    "    \n",
    "    fedfromList = []\n",
    "    for p_x in p_x_list:\n",
    "        fedfromList += [(p_x, p_y) for p_y in p_y_list]\n",
    "        \n",
    "    return fedfromList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_connections(structure, output_sizes):\n",
    "    \"\"\"\n",
    "    A helper function to make the dictionaries for characterizing \n",
    "    the connections of PVM hierarchy\n",
    "    \"\"\"\n",
    "    N_layers = len(structure)\n",
    "    \n",
    "    assert N_layers == len(output_sizes), \\\n",
    "    \"must specify the output sizes such that they match the number of layers\"\n",
    "    \n",
    "    def shape_check(shape):\n",
    "        if isinstance(shape, int):\n",
    "            L_x = shape\n",
    "            L_y = shape\n",
    "        elif len(shape) == 2:\n",
    "            L_x, L_y = shape\n",
    "        elif len(shape) == 1:\n",
    "            L_x = shape[0]\n",
    "            L_y = shape[0]\n",
    "        else:\n",
    "            assert len(shape) < 2 and len(shape) > 0\n",
    "        return L_x, L_y\n",
    "    \n",
    "    ret_name = lambda ls: ['_{0}_{1}_{2}'.format(l, x_, y_)\n",
    "                           for l, x_, y_ in ls]\n",
    "    \n",
    "    connect_dict = OrderedDict()#{}\n",
    "    Unit_count = 0\n",
    "    for layer, shape in enumerate(structure):\n",
    "        output_size = output_sizes[layer]\n",
    "        L_x, L_y = shape_check(shape)\n",
    "        for x in range(L_x):\n",
    "            for y in range(L_y):\n",
    "                name = '_{0}_{1}_{2}'.format(layer, x, y)\n",
    "                \n",
    "                nn_list = []\n",
    "                if x == 0:\n",
    "                    nn_list.append((layer, 1, y))\n",
    "                elif x == L_x-1:\n",
    "                    nn_list.append((layer, x-1, y))\n",
    "                else:\n",
    "                    nn_list += [(layer, x-1, y), (layer, x+1, y)]\n",
    "                if y == 0:\n",
    "                    nn_list.append((layer, x, 1))\n",
    "                elif y == L_y-1:\n",
    "                    nn_list.append((layer, x, y-1))\n",
    "                else:\n",
    "                    nn_list += [(layer, x, y-1), (layer, x, y+1)]\n",
    "                \n",
    "                try:\n",
    "                    feeds2list = feeds2(structure, layer, x, y)\n",
    "                except AssertionError:\n",
    "                    feeds2list = []\n",
    "                try:\n",
    "                    fedfromlist = fedfrom(structure, layer, x, y)\n",
    "                    fedfromlist = [(layer-1, x_, y_) \n",
    "                                   for x_, y_ in fedfromlist]\n",
    "                except AssertionError:\n",
    "                    fedfromlist = []\n",
    "                \n",
    "                if layer < N_layers-2:\n",
    "                    latsuplist = nn_list + [(layer+1, x_, y_)\n",
    "                                            for x_, y_ in feeds2list]\\\n",
    "                                            + [(N_layers-1, 0, 0)]\n",
    "                elif layer == N_layers-2:\n",
    "                    latsuplist = nn_list + [(N_layers-1, 0, 0)]\n",
    "                else:\n",
    "                    latsuplist = [] #None\n",
    "                \n",
    "                try:\n",
    "                    connect_dict[name] = (Unit_count, \n",
    "                                          output_size,\n",
    "                                          ret_name(fedfromlist), \n",
    "                                          ret_name(latsuplist))\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        connect_dict[name] = (Unit_count, \n",
    "                                              output_size,\n",
    "                                              fedfromlist, \n",
    "                                              ret_name(latsuplist))\n",
    "                    except TypeError:\n",
    "                        connect_dict[name] = (Unit_count, \n",
    "                                              output_size,\n",
    "                                              fedfromlist, \n",
    "                                              latsuplist)\n",
    "                except TypeError:\n",
    "                    connect_dict[name] = (Unit_count, \n",
    "                                          output_size,\n",
    "                                          ret_name(fedfromlist), \n",
    "                                          latsuplist)\n",
    "                Unit_count += 1\n",
    "    return connect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connect_dict = make_connections([(16, 16), 8, 4, 3, 2, 1],\n",
    "                                [1, 2*2, 4*4, 8*8, 6*6, 16*16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_initialize(connect_dict, input_size, hidden_size):\n",
    "    \"\"\"\n",
    "    Glorot initializing the weight matrix of each PVM unit based on the\n",
    "    output of the function make_connections or any other ordered dictionary \n",
    "    with keys of the format '_{layer}_{column}_{row}' with values\n",
    "    (unit_count, output_size, fedfromlist, latsuplist)\n",
    "    input_size is the size of the input to one pvm_unit in the lowest layer\n",
    "    \"\"\"\n",
    "    \n",
    "    # lists with mappings for memory shuffling\n",
    "    input_map = [] #full_input[input_map[i]] = input[i]\n",
    "    der_map = [] #full_input[der_map[i]] = der[i]\n",
    "    int_map = [] #full_input[int_map[i]] = integral[i]\n",
    "    err_map = [] #full_input[err_map[i]] = error[i]\n",
    "    \n",
    "    hid_map = [] #full_input[j] = hidden[hid_map[j]] if hid_map[j] != -1\n",
    "    hid_append_map = [] \n",
    "    #input_app[len(input)+i] = hidden[hid_append_map[i]]\n",
    "    \n",
    "    out_map = [] # output[i] = op[out_map[i]]\n",
    "    pred_map = [] # pred[i] = op[pred_map[i]]\n",
    "    \n",
    "    # inputs (+ context) to hidden weights and biases\n",
    "    i2h_bias = []\n",
    "    # weights will be a sparse array in CSR format\n",
    "    i2h_weights  = [] # the values of the weights\n",
    "    i2h_pointers = [0] # sparse array pointers\n",
    "    i2h_indices  = [] # column indices\n",
    "    \n",
    "    # contains the index of each PVM unit in the raw input\n",
    "    input_new_unit = [0] \n",
    "    \n",
    "    # hidden to output & prediction weights and biases\n",
    "    h2op_bias = []\n",
    "    # weights will be a sparse array in CSR format\n",
    "    h2op_weights  = []\n",
    "    h2op_pointers = [0]\n",
    "    h2op_indices  = []\n",
    "    \n",
    "    # contains the index of each PVM unit of the \n",
    "    # output and predictions will be of length N_pmv_units + 1\n",
    "    op_new_unit = [0] \n",
    "    \n",
    "    i2h_col_start = 0\n",
    "    h2op_col_start = 0\n",
    "    for key, val in connect_dict.items():\n",
    "        unit_count, output_size, fedfromlist, latsuplist = val\n",
    "        \n",
    "        # counting the number of units feeding into the array\n",
    "        N_units_feeding_into = len(fedfromlist)\n",
    "        N_units_latsup       = len(latsuplist)\n",
    "        \n",
    "        if N_units_feeding_into == 0:\n",
    "            raw_fed_size = input_size\n",
    "        else:\n",
    "            raw_fed_size = N_units_feeding_into * hidden_size\n",
    "        \n",
    "        # input, derivative, integral, error, hidden and \n",
    "        # lateral/superior context are all contributing to\n",
    "        # the input size to the sigmoid layer\n",
    "        fed_size = 4 * raw_fed_size + (N_units_latsup + 1) * hidden_size\n",
    "        \n",
    "        # prediction of the input and output heatmap\n",
    "        full_output_size = raw_fed_size + output_size\n",
    "        \n",
    "        \n",
    "        i2h_col_end = i2h_col_start + fed_size\n",
    "        # assigning the weights and bias for hidden calculation\n",
    "        for row in range(hidden_size):\n",
    "            # random Gaussian variables with 1/fed_size variance\n",
    "            i2h_weights.append(np.random.randn(fed_size) \n",
    "                               / math.sqrt(fed_size))\n",
    "            i2h_pointers.append(i2h_pointers[-1] + fed_size)\n",
    "            i2h_indices.append(np.arange(i2h_col_start, i2h_col_end))\n",
    "        \n",
    "        i2h_bias.append(np.random.randn(fed_size))\n",
    "        \n",
    "        # the mappings for inputs, derivatives and integral\n",
    "        if key[:2] == '_0':\n",
    "            #raw_fed_size is the same as input_size in this case\n",
    "            input_map += list(range(i2h_col_start,\n",
    "                                    i2h_col_start + input_size))\n",
    "            der_map += list(range(i2h_col_start + input_size,\n",
    "                                  i2h_col_start + 2 * input_size))\n",
    "            int_map += list(range(i2h_col_start + 2 * input_size,\n",
    "                                  i2h_col_start + 3 * input_size))\n",
    "            err_map += list(range(i2h_col_start + 3 * input_size,\n",
    "                                  i2h_col_start + 4 * input_size))\n",
    "        else:\n",
    "            der_map += list(range(i2h_col_start + raw_fed_size,\n",
    "                                  i2h_col_start + 2 * raw_fed_size))\n",
    "            int_map += list(range(i2h_col_start + 2 * raw_fed_size,\n",
    "                                  i2h_col_start + 3 * raw_fed_size))\n",
    "            err_map += list(range(i2h_col_start + 3 * raw_fed_size,\n",
    "                                  i2h_col_start + 4 * raw_fed_size))\n",
    "        \n",
    "        # initialize all hid_map in the relevant range to -1\n",
    "        hid_map += [-1]*(fed_size)\n",
    "        \n",
    "        hid_start = i2h_col_start\n",
    "        hid_end = hid_start + hidden_size\n",
    "        for unit in fedfromlist:\n",
    "            uc = connect_dict[unit][0] #unit count of lat and superior\n",
    "            hid_map[hid_start:hid_end] = list(range(uc \n",
    "                                                    * hidden_size,\n",
    "                                                    (uc + 1)\n",
    "                                                    * hidden_size))\n",
    "            hid_append_map += hid_map[hid_start:hid_end]\n",
    "            hid_start += hidden_size\n",
    "            hid_end   += hidden_size\n",
    "            \n",
    "        \n",
    "        hid_start = i2h_col_start + 4 * raw_fed_size\n",
    "        hid_end = hid_start + hidden_size\n",
    "        \n",
    "        hid_map[hid_start:hid_end] = list(range(unit_count \n",
    "                                                * hidden_size,\n",
    "                                                (unit_count + 1)\n",
    "                                                * hidden_size))\n",
    "        \n",
    "        for unit in latsuplist:\n",
    "            hid_start += hidden_size\n",
    "            hid_end   += hidden_size\n",
    "            uc = connect_dict[unit][0] #unit count of lat and superior\n",
    "            hid_map[hid_start:hid_end] = list(range(uc \n",
    "                                                    * hidden_size,\n",
    "                                                    (uc + 1)\n",
    "                                                    * hidden_size))\n",
    "        \n",
    "        \n",
    "        i2h_col_start = i2h_col_end\n",
    "        input_new_unit.append(i2h_col_start)\n",
    "        \n",
    "        \n",
    "        h2op_col_end = h2op_col_start + hidden_size\n",
    "        # assigning the weights and biases of output + prediction\n",
    "        for row in range(full_output_size):\n",
    "            # random Gaussian variables with 1/hidden_size variance\n",
    "            h2op_weights.append(np.random.randn(hidden_size)\n",
    "                                / math.sqrt(hidden_size))\n",
    "            h2op_pointers.append(h2op_pointers[-1] + hidden_size)\n",
    "            h2op_indices.append(np.arange(h2op_col_start, h2op_col_end))\n",
    "        \n",
    "        h2op_bias.append(np.random.randn(full_output_size))\n",
    "        \n",
    "        new_op_start = op_new_unit[-1]\n",
    "        new_op_out_ends = new_op_start + output_size\n",
    "        new_op_end   = op_new_unit[-1] + full_output_size\n",
    "        out_map  += list(range(new_op_start, new_op_out_ends))\n",
    "        pred_map += list(range(new_op_out_ends, new_op_end))\n",
    "        \n",
    "        h2op_col_start = h2op_col_end\n",
    "        op_new_unit.append(new_op_end)\n",
    "    \n",
    "    i2h_bias      = np.concatenate(i2h_bias,    axis = 0)\n",
    "    i2h_indices   = np.concatenate(i2h_indices, axis = 0)\n",
    "    i2h_weights   = np.concatenate(i2h_weights, axis = 0)\n",
    "    i2h_pointers  = np.array(i2h_pointers, dtype=np.int32)\n",
    "    \n",
    "    h2op_bias     = np.concatenate(h2op_bias,    axis = 0)\n",
    "    h2op_indices  = np.concatenate(h2op_indices, axis = 0)\n",
    "    h2op_weights  = np.concatenate(h2op_weights, axis = 0)\n",
    "    h2op_pointers = np.array(h2op_pointers, dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    return (i2h_pointers, i2h_indices, i2h_weights, i2h_bias),\\\n",
    "           (h2op_pointers, h2op_indices, h2op_weights, h2op_bias),\\\n",
    "           (input_map, der_map, int_map, err_map, hid_map, \n",
    "            hid_append_map, out_map, pred_map),\\\n",
    "            input_new_unit, op_new_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tracker_weight_initialize(structure,\n",
    "                              output_sizes, heatmap_size):\n",
    "    N_layers = len(structure)\n",
    "    \n",
    "    assert N_layers == len(output_sizes), \\\n",
    "    \"must specify the output sizes such that they match the number of layers\"\n",
    "    \n",
    "    def shape_check(shape):\n",
    "        if isinstance(shape, int):\n",
    "            L_x = shape\n",
    "            L_y = shape\n",
    "        elif len(shape) == 2:\n",
    "            L_x, L_y = shape\n",
    "        elif len(shape) == 1:\n",
    "            L_x = shape[0]\n",
    "            L_y = shape[0]\n",
    "        else:\n",
    "            assert len(shape) < 2 and len(shape) > 0\n",
    "        return L_x, L_y\n",
    "    \n",
    "    tracker_bias     = []\n",
    "    tracker_weights  = []\n",
    "    tracker_pointers = [0]\n",
    "    tracker_indices  = []\n",
    "    \n",
    "    \n",
    "    tracker_col_start = 0\n",
    "    for layer in range(N_layers):\n",
    "        L_x, L_y = shape_check(structure[layer])\n",
    "        \n",
    "        output_size = output_sizes[layer]\n",
    "        \n",
    "        tracker_input_size = L_x * L_y * output_size\n",
    "        \n",
    "        tracker_col_end = tracker_col_start + tracker_input_size\n",
    "        for row in range(heatmap_size):\n",
    "            # random Gaussian variables with \n",
    "            # 1/tracker_input_size variance\n",
    "            tracker_weights.append(np.random.randn(tracker_input_size)\n",
    "                                   / math.sqrt(tracker_input_size))\n",
    "            tracker_pointers.append(tracker_pointers[-1]\n",
    "                                    + tracker_input_size)\n",
    "            tracker_indices.append(np.arange(tracker_col_start,\n",
    "                                             tracker_col_end))\n",
    "        \n",
    "        tracker_bias.append(np.random.randn(heatmap_size))\n",
    "        \n",
    "        tracker_col_start = tracker_col_end\n",
    "    \n",
    "    tracker_bias     = np.concatenate(tracker_bias,    axis = 0)\n",
    "    tracker_indices  = np.concatenate(tracker_indices, axis = 0)\n",
    "    tracker_weights  = np.concatenate(tracker_weights, axis = 0)\n",
    "    tracker_pointers = np.array(tracker_pointers, dtype=np.int32)\n",
    "    \n",
    "    return tracker_pointers, tracker_indices, tracker_weights, tracker_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int('_0_1_2'.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs = weight_initialize(connect_dict, 6*6*3, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs[0][0][-1] == len(outs[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs[1][0][-1] == len(outs[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_no_overlap_in_mapping(outs, i):\n",
    "    for idx in outs[2][i]:\n",
    "        if outs[2][4][idx] != -1:\n",
    "            print('We have a problem: ', idx)\n",
    "    print('Done.')\n",
    "\n",
    "for i in range(4):\n",
    "    test_no_overlap_in_mapping(outs, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(outs[2][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs[1][0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outs[1][1][:100], len(outs[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.concatenate([np.array([outs[3]]).T,\n",
    "                np.array([outs[4]]).T], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(outs[3]), len(outs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"./Useful_Kernels.cu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(filename) as fid:\n",
    "    kernel_code = fid.read()\n",
    "    \n",
    "# compile the kernel code\n",
    "mod = compiler.SourceModule(kernel_code)\n",
    "\n",
    "# basic elementwise addition\n",
    "# (I might want to compare the speed \n",
    "# with the default addition hook on gpu arrays)\n",
    "add = mod.get_function('ArrayAddKernel')\n",
    "add.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "# basic elementwise subtraction\n",
    "# (I might want to compare the speed\n",
    "# with the default subtraction hook on gpu arrays)\n",
    "sub = mod.get_function('ArrayDifferenceKernel')\n",
    "sub.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "# basic elementwise multiplication\n",
    "# (I might want to compare the speed\n",
    "# with the default multiplication hook on gpu arrays)\n",
    "hadamard = mod.get_function('HadamardProductKernel')\n",
    "hadamard.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "# All vectors are dense, all matrices are CSR\n",
    "\n",
    "# sets all the elements of an array equal to zero\n",
    "# this is needed for the spmTv_csr_kernel since atomic add is used\n",
    "zerofill = mod.get_function('ZeroFillKernel')\n",
    "zerofill.prepare(['P', np.int32])\n",
    "\n",
    "# outer product that maps result to the shape of the sparse weight matrix\n",
    "# (indices and pointers needed)\n",
    "kron = mod.get_function('spvv_csr_outer_kernel')\n",
    "kron.prepare([np.int32, 'P', 'P', 'P', 'P', 'P'])\n",
    "\n",
    "# sparse matrix-vector multiplication using CSR format \n",
    "dot = mod.get_function('spmv_csr_kernel')\n",
    "dot.prepare([np.int32, 'P', 'P', 'P', 'P', 'P'])\n",
    "\n",
    "# sparse matrix-transpose-vector multiplication using CSR format \n",
    "Tdot = mod.get_function('spmTv_csr_kernel')\n",
    "Tdot.prepare([np.int32, 'P', 'P', 'P', 'P', 'P'])\n",
    "\n",
    "# elementwise application of the sigmoid function\n",
    "sig = mod.get_function('SigmoidKernel')\n",
    "sig.prepare(['P', 'P', np.int32])\n",
    "\n",
    "# elementwise application of the derivative of the sigmoid\n",
    "dsig = mod.get_function('SigmoidPrimeKernel')\n",
    "dsig.prepare(['P', 'P', np.int32])\n",
    "\n",
    "# updating weights and biases\n",
    "update = mod.get_function('UpdateKernel')\n",
    "update.prepare(['P', 'P', np.float64, np.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_filename = \"/home/mhazoglou/CUDA_Kernels/tracker_kernels.cu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(tracker_filename) as fid:\n",
    "    tracker_kernel_code = fid.read()\n",
    "    \n",
    "# compile the kernel code\n",
    "mod_tracker = compiler.SourceModule(tracker_kernel_code)\n",
    "\n",
    "der_and_error = mod_tracker.get_function('der_and_error_kernel')\n",
    "der_and_error.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "integral = mod_tracker.get_function('integral_kernel')\n",
    "integral.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "append_hid = mod_tracker.get_function('hid_append_kernel')\n",
    "append_hid.prepare(['P', 'P', 'P', 'P', np.int32, np.int32])\n",
    "\n",
    "avg_pool = mod_tracker.get_function('tracker_avg_pool_kernel')\n",
    "avg_pool.prepare(['P', 'P', np.int32, np.int32])\n",
    "\n",
    "input_shuffling = mod_tracker.get_function('full_input_map_kernel')\n",
    "input_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "input_hidden_shuffling = mod_tracker.get_function(\\\n",
    "                                        'hidden_map_to_full_input_kernel')\n",
    "input_hidden_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "output_pred_shuffling = mod_tracker.get_function('output_pred_map_kernel')\n",
    "output_pred_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "rev_output_pred_shuffling = mod_tracker.get_function('rev_output_pred_map_kernel')\n",
    "rev_output_pred_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "sq_err_der_tracker = mod_tracker.get_function('SquareErrorDerTrackerKernel')\n",
    "sq_err_der_tracker.prepare(['P', 'P', 'P', np.int32, np.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i2h_stuff, h2op_stuff, map_stuff, input_new_unit, op_new_unit = \\\n",
    "                    weight_initialize(connect_dict, input_size, hidden_size)\n",
    "i2h_pointers, i2h_indices, i2h_weights, i2h_bias = i2h_stuff\n",
    "h2op_pointers, h2op_indices, h2op_weights, h2op_bias = h2op_stuff\n",
    "input_map, der_map, int_map, err_map, hid_map, hid_append_map, out_map,\\\n",
    "                                                        pred_map = map_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_stuff = tracker_weight_initialize(structure,\n",
    "                                          output_sizes, heat_map_size)\n",
    "tracker_pointers, tracker_indices,\\\n",
    "                            tracker_weights, tracker_bias = tracker_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "tracker_w_sparse = sp.csr_matrix((tracker_weights, tracker_indices, tracker_pointers))\n",
    "\n",
    "tracker_pointers[-1] == len(tracker_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i2h_pointers = gpuarray.to_gpu(i2h_pointers)\n",
    "i2h_indices  = gpuarray.to_gpu(i2h_indices)\n",
    "i2h_weights  = gpuarray.to_gpu(i2h_weights)\n",
    "i2h_bias     = gpuarray.to_gpu(i2h_bias)\n",
    "\n",
    "h2op_pointers = gpuarray.to_gpu(h2op_pointers)\n",
    "h2op_indices  = gpuarray.to_gpu(h2op_indices)\n",
    "h2op_weights  = gpuarray.to_gpu(h2op_weights)\n",
    "h2op_bias     = gpuarray.to_gpu(h2op_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_pointers = gpuarray.to_gpu(tracker_pointers)\n",
    "tracker_indices  = gpuarray.to_gpu(tracker_indices)\n",
    "tracker_weights  = gpuarray.to_gpu(tracker_weights)\n",
    "tracker_bias     = gpuarray.to_gpu(tracker_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_hidden_inputs = np.int32(len(hid_append_map)) # length of hidden as inputs\n",
    "L_input = np.int32(len(input_map))\n",
    "\n",
    "# L_pred == len(der_map) == len(int_map) == len(err_map)\n",
    "L_pred = np.int32(len(pred_map)) #same as L_hidden_inputs + L_input\n",
    "L_full_input = np.int32(len(hid_map)) #length of inputs plus context\n",
    "L_out = np.int32(len(out_map))\n",
    "L_op = np.int32(L_out + L_pred)\n",
    "\n",
    "N_units = np.int32(len(connect_dict))\n",
    "N_layers = np.int32(len(structure))\n",
    "\n",
    "L_hidden = np.int32(N_units * hidden_size)\n",
    "L_heatmaps = np.int32(N_layers * heat_map_size)\n",
    "L_avg_heatmap = np.int32(heat_map_size)\n",
    "i2h_weights_nnz = np.int32(len(i2h_weights))\n",
    "h2op_weights_nnz = np.int32(len(h2op_weights))\n",
    "tracker_weights_nnz = np.int32(len(tracker_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxthreads = 1024\n",
    "max_grid_size = 1024\n",
    "grid_x_i2h = min(int(math.ceil(L_hidden/maxthreads)),\n",
    "                 max_grid_size)\n",
    "grid_x_input = min(int(math.ceil(L_input/maxthreads)),\n",
    "                   max_grid_size)\n",
    "grid_x_int_der_err = min(int(math.ceil(L_pred/maxthreads)),\n",
    "                         max_grid_size)\n",
    "grid_x_h2op = min(int(math.ceil(L_op/maxthreads)),\n",
    "                  max_grid_size)\n",
    "grid_x_o_shuf = min(int(math.ceil(L_out/maxthreads)),\n",
    "                    max_grid_size)\n",
    "grid_x_tracker = min(int(math.ceil(L_heatmaps/maxthreads)),\n",
    "                    max_grid_size)\n",
    "grid_x_avgpool = min(int(math.ceil(L_avg_heatmap/maxthreads)),\n",
    "                    max_grid_size)\n",
    "grid_x_update_i2h = min(int(math.ceil(i2h_weights_nnz / maxthreads)),\n",
    "                                max_grid_size)\n",
    "grid_x_update_h2op = min(int(math.ceil(h2op_weights_nnz / maxthreads)),\n",
    "                         max_grid_size)\n",
    "grid_x_update_tracker = min(int(math.ceil(tracker_weights_nnz / maxthreads)),\n",
    "                            max_grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_reformat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_frame = train_data_reformat['green_ball_01_small'][0][0, :]\n",
    "next_frame   = train_data_reformat['green_ball_01_small'][0][1, :]\n",
    "ground_truth_heatmap = train_data_reformat['green_ball_01_small'][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'a':[]}*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_ = next_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data to transfer\n",
    "input_     = gpuarray.to_gpu(single_frame)\n",
    "next_input = gpuarray.to_gpu(next_frame)\n",
    "gt_heatmap = gpuarray.to_gpu(ground_truth_heat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allocating the arrays on the gpu\n",
    "hidden = gpuarray.to_gpu(np.zeros(L_hidden))\n",
    "hid_affine = gpuarray.empty_like(hidden)\n",
    "\n",
    "hidden_inputs = gpuarray.to_gpu(np.zeros(L_hidden_inputs))\n",
    "in_and_hid = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "\n",
    "der  = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "err  = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "int_ = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "\n",
    "out_and_pred = gpuarray.to_gpu(np.zeros(L_op))\n",
    "out_and_pred_affine = gpuarray.empty_like(out_and_pred)\n",
    "\n",
    "pred = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "output = gpuarray.to_gpu(np.zeros(L_out))\n",
    "\n",
    "prev_input = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "full_input = gpuarray.to_gpu(np.zeros(L_full_input))\n",
    "\n",
    "heatmaps = gpuarray.to_gpu(np.zeros(L_heatmaps))\n",
    "heatmaps_affine = gpuarray.empty_like(heatmaps)\n",
    "avg_heatmap = gpuarray.to_gpu(np.zeros(L_avg_heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables for back-propagation\n",
    "ideal_pred    = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "\n",
    "delta_tracker = gpuarray.to_gpu(np.zeros(L_heatmaps))\n",
    "delta_output  = gpuarray.to_gpu(np.zeros(L_out))\n",
    "delta_pred    = gpuarray.to_gpu(np.zeros(L_pred))\n",
    "delta_h2op    = gpuarray.to_gpu(np.zeros(L_op))\n",
    "delta_i2h     = gpuarray.to_gpu(np.zeros(L_hidden))\n",
    "\n",
    "a_prime_tracker = gpuarray.empty_like(heatmaps)\n",
    "a_prime_h2op    = gpuarray.empty_like(out_and_pred)\n",
    "a_prime_i2h     = gpuarray.empty_like(hidden)\n",
    "\n",
    "grad_weight_tracker = gpuarray.empty_like(tracker_weights)\n",
    "grad_weight_h2op    = gpuarray.empty_like(h2op_weights)\n",
    "grad_weight_i2h     = gpuarray.empty_like(i2h_weights)\n",
    "\n",
    "grad_bias_tracker = gpuarray.empty_like(tracker_bias)\n",
    "grad_bias_h2op    = gpuarray.empty_like(h2op_bias)\n",
    "grad_bias_i2h     = gpuarray.empty_like(i2h_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put all maps on gpu for memory shuffling between arrays\n",
    "input_map_gpu = gpuarray.to_gpu(np.array(input_map, dtype=np.int32))\n",
    "der_map_gpu   = gpuarray.to_gpu(np.array(der_map, dtype=np.int32))\n",
    "int_map_gpu   = gpuarray.to_gpu(np.array(int_map, dtype=np.int32))\n",
    "err_map_gpu   = gpuarray.to_gpu(np.array(err_map, dtype=np.int32))\n",
    "hid_map       = gpuarray.to_gpu(np.array(hid_map, dtype=np.int32))\n",
    "hid_append_map = gpuarray.to_gpu(np.array(hid_append_map, dtype=np.int32))\n",
    "out_map_gpu   = gpuarray.to_gpu(np.array(out_map, dtype=np.int32))\n",
    "pred_map_gpu  = gpuarray.to_gpu(np.array(pred_map, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream1 = driver.Stream()\n",
    "stream2 = driver.Stream()\n",
    "stream3 = driver.Stream()\n",
    "stream4 = driver.Stream()\n",
    "stream5 = driver.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "append_hid.prepared_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                         input_.gpudata, hidden.gpudata, in_and_hid.gpudata,\n",
    "                         hid_append_map.gpudata, L_input, L_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_and_hid.get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "der_and_error.prepared_async_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                                  stream1,\n",
    "                                  in_and_hid.gpudata, prev_input.gpudata,\n",
    "                                  der.gpudata, L_pred)\n",
    "der_and_error.prepared_async_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                                  stream2,\n",
    "                                  pred.gpudata, in_and_hid.gpudata,\n",
    "                                  err.gpudata, L_pred)\n",
    "integral.prepared_async_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                             stream3,\n",
    "                             in_and_hid.gpudata, int_.gpudata,\n",
    "                             int_.gpudata, L_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(pred.get() - in_and_hid.get() + 1)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "input_shuffling.prepared_async_call((grid_x_int_der_err, 1),\n",
    "                                    (maxthreads, 1, 1), stream4,\n",
    "                                    full_input.gpudata, input_.gpudata,\n",
    "                                    input_map_gpu.gpudata, L_input)\n",
    "\n",
    "input_hidden_shuffling.prepared_async_call((grid_x_i2h, 1),\n",
    "                                           (maxthreads, 1, 1), stream5,\n",
    "                                           full_input.gpudata, hidden.gpudata,\n",
    "                                           hid_map.gpudata, L_full_input)\n",
    "\n",
    "input_shuffling.prepared_async_call((grid_x_int_der_err, 1),\n",
    "                                    (maxthreads, 1, 1), stream1,\n",
    "                                    full_input.gpudata, der.gpudata,\n",
    "                                    der_map_gpu.gpudata, L_pred)\n",
    "\n",
    "input_shuffling.prepared_async_call((grid_x_int_der_err, 1),\n",
    "                                    (maxthreads, 1, 1), stream2,\n",
    "                                    full_input.gpudata, err.gpudata,\n",
    "                                    err_map_gpu.gpudata, L_pred)\n",
    "\n",
    "input_shuffling.prepared_async_call((grid_x_int_der_err, 1),\n",
    "                                    (maxthreads, 1, 1), stream3,\n",
    "                                    full_input.gpudata, int_.gpudata,\n",
    "                                    int_map_gpu.gpudata, L_pred)\n",
    "\n",
    "prev_input = in_and_hid[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id(prev_input), id(in_and_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prev_input, in_and_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_input[-4000:-3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dot.prepared_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "    # number of rows\n",
    "    L_hidden,\n",
    "    # CSR sparse matrix\n",
    "    i2h_pointers.gpudata, i2h_indices.gpudata, i2h_weights.gpudata,\n",
    "    # vector\n",
    "    full_input.gpudata,\n",
    "    # result\n",
    "    hid_affine.gpudata)\n",
    "\n",
    "add.prepared_call((grid_x_i2h, 1), (maxthreads, 1, 1), \n",
    "    hid_affine.gpudata, i2h_bias.gpudata,\n",
    "    hid_affine.gpudata,\n",
    "    L_hidden)\n",
    "\n",
    "sig.prepared_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "    hid_affine.gpudata, hidden.gpudata,\n",
    "    L_hidden)\n",
    "\n",
    "dot.prepared_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                  # number of rows\n",
    "                  L_op,\n",
    "                  # CSR sparse matrix\n",
    "                  h2op_pointers.gpudata, h2op_indices.gpudata,\n",
    "                  h2op_weights.gpudata,\n",
    "                  #vector\n",
    "                  hidden.gpudata,\n",
    "                  # results\n",
    "                  out_and_pred_affine.gpudata)\n",
    "\n",
    "add.prepared_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                  out_and_pred_affine.gpudata, h2op_bias.gpudata,\n",
    "                  out_and_pred_affine.gpudata,\n",
    "                  L_op)\n",
    "\n",
    "sig.prepared_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                  out_and_pred_affine.gpudata, out_and_pred.gpudata,\n",
    "                  L_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_input.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hid_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "output_pred_shuffling.prepared_async_call((grid_x_o_shuf, 1),\n",
    "                                          (maxthreads, 1, 1), stream4,\n",
    "                                          output.gpudata,\n",
    "                                          out_and_pred.gpudata,\n",
    "                                          out_map_gpu.gpudata, L_out)\n",
    "\n",
    "output_pred_shuffling.prepared_async_call((grid_x_int_der_err, 1),\n",
    "                                          (maxthreads, 1, 1), stream5,\n",
    "                                          pred.gpudata,\n",
    "                                          out_and_pred.gpudata,\n",
    "                                          pred_map_gpu.gpudata, L_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_and_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dot.prepared_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                  # number of rows\n",
    "                  L_heatmaps,\n",
    "                  # CSR sparse matrix\n",
    "                  tracker_pointers.gpudata, tracker_indices.gpudata,\n",
    "                  tracker_weights.gpudata,\n",
    "                  #vector\n",
    "                  output.gpudata,\n",
    "                  # results\n",
    "                  heatmaps_affine.gpudata)\n",
    "\n",
    "add.prepared_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                  heatmaps_affine.gpudata, tracker_bias.gpudata,\n",
    "                  heatmaps_affine.gpudata,\n",
    "                  L_heatmaps)\n",
    "\n",
    "sig.prepared_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                  heatmaps_affine.gpudata, heatmaps.gpudata, L_heatmaps)\n",
    "\n",
    "avg_pool.prepared_call((grid_x_avgpool, 1), (maxthreads, 1, 1),\n",
    "                       heatmaps.gpudata, avg_heatmap.gpudata,\n",
    "                       L_avg_heatmap, N_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = gpuarray.to_gpu(np.ones(L_heatmaps))\n",
    "out_test = gpuarray.to_gpu(np.zeros(L_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpu_result = (tracker_w_sparse.transpose()).dot(np.ones(L_heatmaps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpu_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tdot.prepared_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                         L_heatmaps,\n",
    "                         tracker_pointers.gpudata, tracker_indices.gpudata,\n",
    "                         tracker_weights.gpudata,\n",
    "                         #vector\n",
    "                         test.gpudata,\n",
    "                         # results\n",
    "                         out_test.gpudata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(sum((cpu_result - out_test.get())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max(tracker_indices.get()), L_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsig.prepared_async_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "                         stream1,\n",
    "                         hid_affine.gpudata, a_prime_i2h.gpudata, L_hidden)\n",
    "\n",
    "dsig.prepared_async_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                         stream2,\n",
    "                         heatmaps_affine.gpudata,\n",
    "                         a_prime_tracker.gpudata, L_heatmaps)\n",
    "\n",
    "dsig.prepared_async_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                         stream3,\n",
    "                         out_and_pred_affine.gpudata, a_prime_h2op.gpudata, L_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1/(1 + np.exp(-hid_affine.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = 1/(1 + np.exp(-hid_affine.get()))\n",
    "s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_prime_i2h.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "append_hid.prepared_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                         next_input.gpudata, hidden.gpudata, ideal_pred.gpudata,\n",
    "                         hid_append_map.gpudata, L_input, L_pred)\n",
    "\n",
    "sub.prepared_async_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                        stream1,\n",
    "                        pred.gpudata, ideal_pred.gpudata,\n",
    "                        delta_pred.gpudata, L_pred)\n",
    "\n",
    "sq_err_der_tracker.prepared_async_call((grid_x_avgpool, 1), (maxthreads, 1, 1),\n",
    "                                       stream2,\n",
    "                                       avg_heatmap.gpudata, gt_heatmap.gpudata,\n",
    "                                       delta_tracker.gpudata, L_avg_heatmap, N_layers)\n",
    "\n",
    "\n",
    "\n",
    "hadamard.prepared_async_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                             stream2,\n",
    "                             delta_tracker.gpudata, a_prime_tracker.gpudata,\n",
    "                             delta_tracker.gpudata, L_heatmaps)\n",
    "\n",
    "zerofill.prepared_async_call((grid_x_o_shuf, 1), (maxthreads, 1, 1),\n",
    "                             stream2,\n",
    "                             delta_output.gpudata, L_out)\n",
    "\n",
    "# data type issue 446464 is the values pointers goes up to but 65535 is unsigned int range\n",
    "# need to change unsigned int to unsigned long int\n",
    "Tdot.prepared_async_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                         stream2,\n",
    "                         L_heatmaps,\n",
    "                         tracker_pointers.gpudata, tracker_indices.gpudata,\n",
    "                         tracker_weights.gpudata,\n",
    "                         #vector\n",
    "                         delta_tracker.gpudata,\n",
    "                         # results\n",
    "                         delta_output.gpudata)\n",
    "\n",
    "rev_output_pred_shuffling.prepared_async_call((grid_x_int_der_err, 1), (maxthreads, 1, 1),\n",
    "                                              stream1,\n",
    "                                              delta_pred.gpudata, delta_h2op.gpudata,\n",
    "                                              pred_map_gpu.gpudata, L_pred)\n",
    "\n",
    "rev_output_pred_shuffling.prepared_async_call((grid_x_o_shuf, 1), (maxthreads, 1, 1),\n",
    "                                              stream2,\n",
    "                                              delta_output.gpudata, delta_h2op.gpudata,\n",
    "                                              out_map_gpu.gpudata, L_out)\n",
    "\n",
    "\n",
    "\n",
    "hadamard.prepared_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                       delta_h2op.gpudata, a_prime_h2op.gpudata,\n",
    "                       delta_h2op.gpudata, L_op)\n",
    "\n",
    "zerofill.prepared_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "                       delta_i2h.gpudata, L_hidden)\n",
    "\n",
    "Tdot.prepared_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                   L_op,\n",
    "                   h2op_pointers.gpudata, h2op_indices.gpudata,\n",
    "                   h2op_weights.gpudata,\n",
    "                   delta_h2op.gpudata,\n",
    "                   delta_i2h.gpudata)\n",
    "\n",
    "hadamard.prepared_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "                       delta_i2h.gpudata, a_prime_i2h.gpudata,\n",
    "                       delta_i2h.gpudata, L_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = np.float64(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "kron.prepared_async_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "                         stream1,\n",
    "                         L_hidden, i2h_pointers.gpudata, i2h_indices.gpudata,\n",
    "                         delta_i2h.gpudata, hidden.gpudata,\n",
    "                         grad_weight_i2h.gpudata)\n",
    "\n",
    "kron.prepared_async_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                         stream2,\n",
    "                         L_op, h2op_pointers.gpudata, h2op_indices.gpudata,\n",
    "                         delta_h2op.gpudata, out_and_pred.gpudata,\n",
    "                         grad_weight_h2op.gpudata)\n",
    "\n",
    "kron.prepared_async_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                         stream3,\n",
    "                         L_heatmaps, tracker_pointers.gpudata, tracker_indices.gpudata,\n",
    "                         delta_tracker.gpudata, heatmaps.gpudata,\n",
    "                         grad_weight_tracker.gpudata)\n",
    "\n",
    "update.prepared_async_call((grid_x_i2h, 1), (maxthreads, 1, 1),\n",
    "                           stream1,\n",
    "                           i2h_bias.gpudata, delta_i2h.gpudata,\n",
    "                           lr, L_hidden)\n",
    "\n",
    "update.prepared_async_call((grid_x_h2op, 1), (maxthreads, 1, 1),\n",
    "                           stream2,\n",
    "                           h2op_bias.gpudata, delta_h2op.gpudata,\n",
    "                           lr, L_op)\n",
    "\n",
    "update.prepared_async_call((grid_x_tracker, 1), (maxthreads, 1, 1),\n",
    "                           stream3,\n",
    "                           tracker_bias.gpudata, delta_tracker.gpudata, \n",
    "                           lr, L_heatmaps)\n",
    "\n",
    "update.prepared_async_call((grid_x_update_i2h, 1), (maxthreads, 1, 1),\n",
    "                           stream1,\n",
    "                           i2h_weights.gpudata, grad_weight_i2h.gpudata,\n",
    "                           lr, i2h_weights_nnz)\n",
    "\n",
    "update.prepared_async_call((grid_x_update_h2op, 1), (maxthreads, 1, 1),\n",
    "                           stream2,\n",
    "                           h2op_weights.gpudata, grad_weight_h2op.gpudata,\n",
    "                           lr, h2op_weights_nnz)\n",
    "\n",
    "update.prepared_async_call((grid_x_update_tracker, 1), (maxthreads, 1, 1),\n",
    "                           stream3,\n",
    "                           tracker_weights.gpudata, grad_weight_tracker.gpudata, \n",
    "                           lr, tracker_weights_nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_weight_i2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_weight_h2op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_weight_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_weights, i2h_weights, h2op_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_tracker.get()[1::256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_output.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_h2op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_i2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_indices.get()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracker_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_heatmaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
