{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycuda._driver.Function at 0x7f9b4e068938>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, print_function, division\n",
    "from builtins import *\n",
    "import math\n",
    "import cPickle as cP\n",
    "# from collections import OrderedDict\n",
    "import numpy as np\n",
    "from pycuda import driver, compiler, gpuarray, tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_DEVICE'] = '0'\n",
    "\n",
    "#-- initialize the device\n",
    "import pycuda.autoinit\n",
    "\n",
    "fname = \"/home/mhazoglou/PVM_PyCUDA/Useful_Kernels.cu\"\n",
    "tracker_filename = \"/home/mhazoglou/PVM_PyCUDA/tracker_kernels.cu\"\n",
    "\n",
    "with open(fname) as fid:\n",
    "    kernel_code = fid.read()\n",
    "\n",
    "with open(tracker_filename) as fid:\n",
    "    tracker_kernel_code = fid.read()\n",
    "\n",
    "# compile the kernel code\n",
    "mod = compiler.SourceModule(kernel_code)\n",
    "\n",
    "# basic element-wise addition\n",
    "# (I might want to compare the speed\n",
    "# with the default addition hook on gpu arrays)\n",
    "add = mod.get_function('ArrayAddKernel')\n",
    "add.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "# basic element-wise subtraction\n",
    "# (I might want to compare the speed\n",
    "# with the default subtraction hook on gpu arrays)\n",
    "sub = mod.get_function('ArrayDifferenceKernel')\n",
    "sub.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "# basic element-wise multiplication\n",
    "# (I might want to compare the speed\n",
    "# with the default multiplication hook on gpu arrays)\n",
    "hadamard = mod.get_function('HadamardProductKernel')\n",
    "hadamard.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "# All vectors are dense, all matrices are CSR\n",
    "\n",
    "# sets all the elements of an array equal to zero\n",
    "# this is needed for the spmTv_csr_kernel since atomic add is used\n",
    "zerofill = mod.get_function('ZeroFillKernel')\n",
    "zerofill.prepare(['P', np.int32])\n",
    "\n",
    "# outer product that maps result to the shape of the sparse weight matrix\n",
    "# (indices and pointers needed)\n",
    "kron = mod.get_function('spvv_coo_outer_kernel')\n",
    "kron.prepare([np.int32, 'P', 'P', 'P', 'P', 'P'])\n",
    "\n",
    "# sparse matrix-vector multiplication using CSR format\n",
    "dot = mod.get_function('spmv_csr_kernel')\n",
    "dot.prepare([np.int32, 'P', 'P', 'P', 'P', 'P'])\n",
    "\n",
    "# sparse matrix-transpose-vector multiplication using CSR format\n",
    "Tdot = mod.get_function('spmTv_csr_kernel')\n",
    "Tdot.prepare([np.int32, 'P', 'P', 'P', 'P', 'P'])\n",
    "\n",
    "# element-wise application of the sigmoid function\n",
    "sig = mod.get_function('SigmoidKernel')\n",
    "sig.prepare(['P', 'P', np.int32])\n",
    "\n",
    "# element-wise application of the derivative of the sigmoid\n",
    "dsig = mod.get_function('SigmoidPrimeKernel')\n",
    "dsig.prepare(['P', 'P', np.int32])\n",
    "\n",
    "# updating weights and biases\n",
    "update = mod.get_function('UpdateKernel')\n",
    "update.prepare(['P', 'P', np.float64, np.int32])\n",
    "\n",
    "# --------------------Tracker functions--------------------\n",
    "# compile the kernel code\n",
    "mod_tracker = compiler.SourceModule(tracker_kernel_code)\n",
    "\n",
    "der_and_error = mod_tracker.get_function('der_and_error_kernel')\n",
    "der_and_error.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "integral = mod_tracker.get_function('integral_kernel')\n",
    "integral.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "append_hid = mod_tracker.get_function('hid_append_kernel')\n",
    "append_hid.prepare(['P', 'P', 'P', 'P', np.int32, np.int32])\n",
    "\n",
    "avg_pool = mod_tracker.get_function('tracker_avg_pool_kernel')\n",
    "avg_pool.prepare(['P', 'P', np.int32, np.int32])\n",
    "\n",
    "input_shuffling = mod_tracker.get_function('full_input_map_kernel')\n",
    "input_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "input_hidden_shuffling = mod_tracker.get_function(\n",
    "                                        'hidden_map_to_full_input_kernel')\n",
    "input_hidden_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "output_pred_shuffling = mod_tracker.get_function('output_pred_map_kernel')\n",
    "output_pred_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "rev_output_pred_shuffling = mod_tracker.get_function(\n",
    "    'rev_output_pred_map_kernel')\n",
    "rev_output_pred_shuffling.prepare(['P', 'P', 'P', np.int32])\n",
    "\n",
    "sq_err_der_tracker = mod_tracker.get_function('SquareErrorDerTrackerKernel')\n",
    "sq_err_der_tracker.prepare(['P', 'P', 'P', np.int32, np.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_0 = 10\n",
    "size_1 = 10\n",
    "hidden_size = 4\n",
    "spec_dict = {'auto_0': size_0, 'auto_1': size_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto_0': 10, 'auto_1': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctored_data = {}\n",
    "for x in range(1000):\n",
    "    doctored_data[str(x)] = (np.random.rand(size_0 + size_1),) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.21361497,  0.3086147 ,  0.96228335,  0.47528808,  0.23232394,\n",
       "         0.92805817,  0.9557962 ,  0.33402053,  0.70923288,  0.02099854,\n",
       "         0.18963301,  0.34300841,  0.65660284,  0.36406319,  0.82829515,\n",
       "         0.3227624 ,  0.83692675,  0.79205675,  0.80539949,  0.36288741]),\n",
       " array([ 0.21361497,  0.3086147 ,  0.96228335,  0.47528808,  0.23232394,\n",
       "         0.92805817,  0.9557962 ,  0.33402053,  0.70923288,  0.02099854,\n",
       "         0.18963301,  0.34300841,  0.65660284,  0.36406319,  0.82829515,\n",
       "         0.3227624 ,  0.83692675,  0.79205675,  0.80539949,  0.36288741]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctored_data['10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movingaverage(interval, window_size):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    return np.convolve(interval, window, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelAutoencoder(object):\n",
    "    def __init__(self, spec_dict, hidden_size, max_threads=1024, max_grid_size=1024):\n",
    "        i2h_stuff, h2p_stuff = self.weight_initialize(spec_dict, hidden_size)\n",
    "        i2h_pointers, i2h_indices, i2h_weights, i2h_bias = i2h_stuff\n",
    "        h2p_pointers, h2p_indices, h2p_weights, h2p_bias = h2p_stuff\n",
    "        \n",
    "        self.i2h_pointers = gpuarray.to_gpu(i2h_pointers)\n",
    "        self.i2h_indices  = gpuarray.to_gpu(i2h_indices)\n",
    "        self.i2h_weights  = gpuarray.to_gpu(i2h_weights)\n",
    "        self.i2h_bias     = gpuarray.to_gpu(i2h_bias)\n",
    "        \n",
    "        self.i2h_row_idx = gpuarray.to_gpu(self.ptr_to_row(i2h_pointers))\n",
    "        \n",
    "        self.h2p_pointers = gpuarray.to_gpu(h2p_pointers)\n",
    "        self.h2p_indices  = gpuarray.to_gpu(h2p_indices)\n",
    "        self.h2p_weights  = gpuarray.to_gpu(h2p_weights)\n",
    "        self.h2p_bias     = gpuarray.to_gpu(h2p_bias)\n",
    "        \n",
    "        self.h2p_row_idx = gpuarray.to_gpu(self.ptr_to_row(h2p_pointers))\n",
    "        \n",
    "        self.L_hidden = np.int32(len(i2h_bias))\n",
    "        self.L_pred   = np.int32(len(h2p_bias))\n",
    "        \n",
    "        self.i2h_weights_nnz = np.int32(i2h_pointers[-1])\n",
    "        self.h2p_weights_nnz = np.int32(h2p_pointers[-1])\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.hidden = gpuarray.to_gpu(np.zeros(self.L_hidden))\n",
    "        self.pred   = gpuarray.to_gpu(np.zeros(self.L_pred))\n",
    "        \n",
    "        self.hid_affine  = gpuarray.empty_like(self.hidden)\n",
    "        self.pred_affine = gpuarray.empty_like(self.pred)\n",
    "        \n",
    "        self.delta_h2p = gpuarray.to_gpu(np.zeros(self.L_pred))\n",
    "        self.delta_i2h = gpuarray.to_gpu(np.zeros(self.L_hidden))\n",
    "        \n",
    "        self.a_prime_h2p = gpuarray.empty_like(self.pred)\n",
    "        self.a_prime_i2h  = gpuarray.empty_like(self.hidden)\n",
    "        \n",
    "        self.grad_weight_h2p  = gpuarray.empty_like(self.h2p_weights)\n",
    "        self.grad_weight_i2h  = gpuarray.empty_like(self.i2h_weights)\n",
    "        \n",
    "        ceil = lambda x: int(math.ceil(x))\n",
    "        self.threads = (max_threads, 1, 1)\n",
    "        grid_x_i2h = min(ceil(self.L_hidden / max_threads), max_grid_size)\n",
    "        grid_x_h2p = min(ceil(self.L_pred / max_threads), max_grid_size)\n",
    "        grid_x_update_i2h = min(ceil(self.i2h_weights_nnz / max_threads), max_grid_size)\n",
    "        grid_x_update_h2p = min(ceil(self.h2p_weights_nnz / max_threads), max_grid_size)\n",
    "        \n",
    "        self.grid_i2h = (grid_x_i2h, 1)\n",
    "        self.grid_h2p = (grid_x_h2p, 1)\n",
    "        self.grid_update_i2h = (grid_x_update_i2h, 1)\n",
    "        self.grid_update_h2p = (grid_x_update_h2p, 1)\n",
    "        \n",
    "        self.stream1 = driver.Stream()\n",
    "        self.stream2 = driver.Stream()\n",
    "        self.stream3 = driver.Stream()\n",
    "        self.stream4 = driver.Stream()\n",
    "        self.stream5 = driver.Stream()\n",
    "        \n",
    "        self.sq_err = []\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        input_gpu = gpuarray.to_gpu(input_)\n",
    "        \n",
    "        dot.prepared_call(self.grid_i2h, self.threads,\n",
    "                          # number of rows\n",
    "                          self.L_hidden,\n",
    "                          # CSR sparse matrix\n",
    "                          self.i2h_pointers.gpudata,\n",
    "                          self.i2h_indices.gpudata,\n",
    "                          self.i2h_weights.gpudata,\n",
    "                          # vector\n",
    "                          input_gpu.gpudata,\n",
    "                          # result\n",
    "                          self.hid_affine.gpudata)\n",
    "        \n",
    "        add.prepared_call(self.grid_i2h, self.threads,\n",
    "                          self.hid_affine.gpudata, self.i2h_bias.gpudata,\n",
    "                          self.hid_affine.gpudata, self.L_hidden)\n",
    "        \n",
    "        sig.prepared_call(self.grid_i2h, self.threads,\n",
    "                          self.hid_affine.gpudata, self.hidden.gpudata,\n",
    "                          self.L_hidden)\n",
    "        \n",
    "        dot.prepared_call(self.grid_h2p, self.threads,\n",
    "                          self.L_pred,\n",
    "                          self.h2p_pointers.gpudata,\n",
    "                          self.h2p_indices.gpudata,\n",
    "                          self.h2p_weights.gpudata,\n",
    "                          self.hidden.gpudata,\n",
    "                          self.pred_affine.gpudata)\n",
    "        \n",
    "        add.prepared_call(self.grid_h2p, self.threads, \n",
    "                          self.pred_affine.gpudata, self.h2p_bias.gpudata,\n",
    "                          self.pred_affine.gpudata, self.L_pred)\n",
    "        \n",
    "        sig.prepared_call(self.grid_h2p, self.threads,\n",
    "                          self.pred_affine.gpudata, self.pred.gpudata,\n",
    "                          self.L_pred)\n",
    "        \n",
    "    def _backward(self, input_, ideal_pred, learning_rate):\n",
    "        # should be called only after forward is called first\n",
    "        input_gpu = gpuarray.to_gpu_async(input_, stream=self.stream1)\n",
    "        ideal_pred_gpu = gpuarray.to_gpu_async(ideal_pred, stream=self.stream2)\n",
    "        \n",
    "        dsig.prepared_async_call(self.grid_i2h, self.threads,\n",
    "                                 self.stream3,\n",
    "                                 self.hid_affine.gpudata, self.a_prime_i2h.gpudata,\n",
    "                                 self.L_hidden)\n",
    "        \n",
    "        dsig.prepared_async_call(self.grid_h2p, self.threads,\n",
    "                                 self.stream4,\n",
    "                                 self.pred_affine.gpudata, self.a_prime_h2p.gpudata,\n",
    "                                 self.L_pred)\n",
    "        \n",
    "        sub.prepared_async_call(self.grid_h2p, self.threads,\n",
    "                                self.stream5,\n",
    "                                self.pred.gpudata, ideal_pred_gpu.gpudata,\n",
    "                                self.delta_h2p.gpudata,\n",
    "                                self.L_pred)\n",
    "        \n",
    "        hadamard.prepared_call(self.grid_h2p, self.threads,\n",
    "                               self.delta_h2p.gpudata, self.a_prime_h2p.gpudata,\n",
    "                               self.delta_h2p.gpudata,\n",
    "                               self.L_pred)\n",
    "        \n",
    "        zerofill.prepared_call(self.grid_i2h, self.threads,\n",
    "                               self.delta_i2h.gpudata, self.L_hidden)\n",
    "        \n",
    "        Tdot.prepared_call(self.grid_h2p, self.threads,\n",
    "                           self.L_pred, self.h2p_pointers.gpudata,\n",
    "                           self.h2p_indices.gpudata, self.h2p_weights.gpudata,\n",
    "                           self.delta_h2p.gpudata, self.delta_i2h.gpudata)\n",
    "        \n",
    "        hadamard.prepared_call(self.grid_i2h, self.threads,\n",
    "                               self.delta_i2h.gpudata, self.a_prime_i2h.gpudata,\n",
    "                               self.delta_i2h.gpudata,\n",
    "                               self.L_hidden)\n",
    "        \n",
    "        kron.prepared_async_call(self.grid_i2h, self.threads,\n",
    "                                 self.stream1,\n",
    "                                 self.i2h_weights_nnz,\n",
    "                                 self.i2h_row_idx.gpudata,\n",
    "                                 self.i2h_indices.gpudata,\n",
    "                                 input_gpu.gpudata, self.delta_i2h.gpudata,\n",
    "                                 self.grad_weight_i2h.gpudata)\n",
    "\n",
    "        kron.prepared_async_call(self.grid_h2p, self.threads,\n",
    "                                 self.stream2,\n",
    "                                 self.h2p_weights_nnz,\n",
    "                                 self.h2p_row_idx.gpudata,\n",
    "                                 self.h2p_indices.gpudata,\n",
    "                                 self.hidden.gpudata,\n",
    "                                 self.delta_h2p.gpudata,\n",
    "                                 self.grad_weight_h2p.gpudata)\n",
    "        \n",
    "        update.prepared_async_call(self.grid_update_i2h, self.threads,\n",
    "                                   self.stream1, \n",
    "                                   self.i2h_weights.gpudata,\n",
    "                                   self.grad_weight_i2h.gpudata, learning_rate,\n",
    "                                   self.i2h_weights_nnz)\n",
    "        \n",
    "        update.prepared_async_call(self.grid_update_h2p, self.threads,\n",
    "                                   self.stream2,\n",
    "                                   self.h2p_weights.gpudata,\n",
    "                                   self.grad_weight_i2h.gpudata, learning_rate,\n",
    "                                   self.h2p_weights_nnz)\n",
    "        \n",
    "        update.prepared_async_call(self.grid_i2h, self.threads,\n",
    "                                   self.stream3,\n",
    "                                   self.i2h_bias.gpudata, self.delta_i2h.gpudata,\n",
    "                                   learning_rate, self.L_hidden)\n",
    "        \n",
    "        update.prepared_async_call(self.grid_h2p, self.threads,\n",
    "                                   self.stream4, self.h2p_bias.gpudata,\n",
    "                                   self.delta_h2p.gpudata, learning_rate,\n",
    "                                   self.L_pred)\n",
    "    \n",
    "    def train(self, train_dict, learning_rate_list, print_every=100,\n",
    "              save_every_print=False, filename='default', interval=100):\n",
    "        L_lr = len(learning_rate_list)\n",
    "        n = 0\n",
    "        while n < L_lr:\n",
    "            for key, training_data in train_dict.items():\n",
    "                input_, ideal_pred = training_data\n",
    "                self.forward(input_)\n",
    "                self._backward(input_, ideal_pred, learning_rate_list[n])\n",
    "                n += 1\n",
    "                se = sum((ideal_pred - self.pred.get())**2) / 2.\n",
    "                self.sq_err.append(se)\n",
    "                if n % print_every == 0:\n",
    "                    mse = sum(self.sq_err[-print_every:]) /\\\n",
    "                                  print_every\n",
    "                    print(\"{:>10} frames: {:>10}\".format(n, mse))\n",
    "                if save_every_print:\n",
    "                    self.save_parameters(filename)\n",
    "                    plt.plot(movingaverage(self.sq_err, interval))\n",
    "                    plt.savefig(filename +\n",
    "                                '_training_moving_avg' +\n",
    "                                '_SqErr_vs_frames.pdf',\n",
    "                                transparent=True)\n",
    "                    plt.close()\n",
    "                if n == L_lr:\n",
    "                    break\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def weight_initialize(spec_dict, hidden_size):\n",
    "        # input to hidden\n",
    "        i2h_pointers = [0]\n",
    "        i2h_indices = []\n",
    "        i2h_weights = []\n",
    "        i2h_bias = []\n",
    "        # hidden to predictions\n",
    "        h2p_pointers = [0]\n",
    "        h2p_indices = []\n",
    "        h2p_weights = []\n",
    "        h2p_bias = []\n",
    "        \n",
    "        sum_size = 0\n",
    "        unit_count = 0\n",
    "        for key, size in spec_dict.items():\n",
    "            for _ in range(hidden_size):\n",
    "                i2h_pointers.append(i2h_pointers[-1] + size)\n",
    "                i2h_indices.append(sum_size + np.arange(size))\n",
    "                i2h_weights.append(np.random.randn(size) / math.sqrt(size))\n",
    "            i2h_bias.append(np.random.randn(hidden_size))\n",
    "            sum_size += size\n",
    "            \n",
    "            for _ in range(size):\n",
    "                h2p_pointers.append(h2p_pointers[-1] + hidden_size)\n",
    "                h2p_indices.append(np.arange(unit_count * hidden_size,\n",
    "                                             (unit_count + 1) * hidden_size))\n",
    "                h2p_weights.append(np.random.randn(hidden_size) / \n",
    "                                   math.sqrt(hidden_size))\n",
    "            h2p_bias.append(np.random.randn(size))\n",
    "            unit_count += 1\n",
    "        \n",
    "        i2h_pointers = np.array(i2h_pointers)\n",
    "        i2h_weights = np.concatenate(i2h_weights)\n",
    "        i2h_bias = np.concatenate(i2h_bias)\n",
    "        i2h_indices = np.concatenate(i2h_indices)\n",
    "        \n",
    "        h2p_pointers = np.array(h2p_pointers)\n",
    "        h2p_weights = np.concatenate(h2p_weights)\n",
    "        h2p_bias = np.concatenate(h2p_bias)\n",
    "        h2p_indices = np.concatenate(h2p_indices)\n",
    "        \n",
    "        return (i2h_pointers, i2h_indices, i2h_weights, i2h_bias), \\\n",
    "            (h2p_pointers, h2p_indices, h2p_weights, h2p_bias)\n",
    "    \n",
    "    @staticmethod\n",
    "    def ptr_to_row(ptr):\n",
    "        \"\"\"\n",
    "        Converts the input array-like of pointer (CSR format)\n",
    "        to the equivalent array or rows for conversion of CSR\n",
    "        to COO.\n",
    "\n",
    "        :param ptr: An array like of pointers as is found in\n",
    "        CSR format.\n",
    "        :return: A numpy array for corresponding row indices of\n",
    "        the input ptr\n",
    "        \"\"\"\n",
    "        L_ptr = len(ptr)\n",
    "        row_idx = []\n",
    "        for idx, ptr_idx in enumerate(range(L_ptr - 1)):\n",
    "            row_idx += [idx] * (ptr[ptr_idx + 1] - ptr[ptr_idx])\n",
    "        return np.array(row_idx, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auto = ParallelAutoencoder(spec_dict, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,) (8,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-340bc58ce267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m auto.train(doctored_data, learning_rate_list, print_every=1000,\n\u001b[0;32m----> 3\u001b[0;31m               save_every_print=False, filename='default', interval=100)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-9a7bcacad0f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dict, learning_rate_list, print_every, save_every_print, filename, interval)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mideal_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mideal_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msq_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (20,) (8,) "
     ]
    }
   ],
   "source": [
    "learning_rate_list = [0.001]*10000\n",
    "auto.train(doctored_data, learning_rate_list, print_every=1000,\n",
    "              save_every_print=False, filename='default', interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParallelAutoencoder.weight_initialize(spec_dict, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47705691,  0.67229635,  0.25865827,  0.55470264,  0.58600763,\n",
       "        0.74416861,  0.89767121,  0.22183611])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.L_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
